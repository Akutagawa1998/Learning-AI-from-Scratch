{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a248634b",
   "metadata": {},
   "source": [
    "# MNIST Training\n",
    "## Day 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e66b8793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# DataLoader是用于加载数据集的模块\n",
    "import torchvision\n",
    "# transforms是数据预处理模块，用于将图像转换为张量，并进行归一化\n",
    "import torchvision.transforms as transforms\n",
    "# datasets是用于加载数据集的模块\n",
    "from torchvision import datasets\n",
    "# DataLoader是用于加载数据集的模块\n",
    "from torch.utils.data import DataLoader  # 添加这一行\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.patheffects as path_effects\n",
    "import matplotlib.patheffects as path_effects\n",
    "import os\n",
    "import torch.utils.data as data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca450df",
   "metadata": {},
   "source": [
    "### Q: datasets和Dataloader的区别是什么?\n",
    "#### datasets 和 DataLoader 的区别\n",
    "1. datasets（数据集类）\n",
    "作用：定义和加载数据集，提供对原始数据的访问。\n",
    "特点：\n",
    "负责数据获取、下载、存储\n",
    "应用数据预处理（如 transform）\n",
    "返回一个数据集对象，包含所有样本\n",
    "可通过索引访问单个样本：dataset[0] 返回一个样本\n",
    "\"\"\"\n",
    "train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "# train_ds 包含所有 60,000 个训练样本\n",
    "# 可以通过 train_ds[0] 访问第一个样本（图像和标签）\n",
    "\"\"\"\n",
    "\n",
    "2. DataLoader（数据加载器）\n",
    "作用：将数据集包装成可迭代的批次，用于训练循环。\n",
    "特点：\n",
    "将数据集分成批次（batch）\n",
    "支持多进程加载（num_workers）\n",
    "支持打乱顺序（shuffle）\n",
    "支持内存固定（pin_memory，用于 GPU 加速）\n",
    "返回一个迭代器，每次迭代返回一个批次的数据\n",
    "示例：\n",
    "\"\"\"\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "# train_loader 将 60,000 个样本分成多个批次，每批 128 个样本\n",
    "# 在训练循环中使用：\n",
    "for images, labels in train_loader:\n",
    "    # images: [128, 1, 28, 28] 形状的张量（128个图像）\n",
    "    # labels: [128] 形状的张量（128个标签）\n",
    "    # 进行训练...\n",
    "\"\"\"\n",
    "\n",
    "3. 关系和工作流程\n",
    "原始数据 → datasets.MNIST → 数据集对象 → DataLoader → 批次迭代器 → 训练循环\n",
    "         (加载和预处理)    (所有样本)    (分批处理)    (批量数据)\n",
    "在我们的代码中：\n",
    "\"\"\"\n",
    "# 步骤1: 创建数据集（包含所有样本）\n",
    "train_ds = datasets.MNIST(...)  # 60,000 个样本\n",
    "\n",
    "# 步骤2: 创建数据加载器（将数据集分批）\n",
    "train_loader = DataLoader(train_ds, batch_size=128, ...)  # 约 469 个批次\n",
    "\n",
    "# 步骤3: 在训练中使用\n",
    "for batch_images, batch_labels in train_loader:\n",
    "    # 每次循环处理 128 个样本\n",
    "    pass\n",
    "\"\"\"\n",
    "\n",
    "4. 简单类比\n",
    "datasets = 图书馆（存放所有书籍）\n",
    "DataLoader = 借书系统（每次借出几本书，可以按顺序或随机借）\n",
    "总结：datasets 负责数据的定义和访问，DataLoader 负责将数据组织成批次供训练使用。两者配合使用，datasets 提供数据源，DataLoader 提供高效的批量加载机制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fd65b9",
   "metadata": {},
   "source": [
    "#### Task 0: 使用合适的device(cuda,mps,cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "761dd0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c313470",
   "metadata": {},
   "source": [
    "#### Task 1: 进行数据预处理，download并加载MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe23021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "# 将图像转换为张量，并进行归一化\n",
    "# 0.1307 是 MNIST 数据集的均值，0.3081 是 MNIST 数据集的标准差, 这两个数据是从MNIST数据集的官方网站上获取的，如果之后的数据集没有这些公开数据，则需要重新计算\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# ds是数据集的缩写，train_ds是训练数据集，val_ds是验证数据集\n",
    "# 从MNIST数据集官网下载数据集，并进行预处理\n",
    "# 下载的数据集会保存在./data/MNIST文件夹下\n",
    "# 我们已经有数据集了，所以不需要下载，因此先检查是否存在    \n",
    " # 如果数据集不存在，则从MNIST数据集官网下载数据集\n",
    "train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "val_ds = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d83269",
   "metadata": {},
   "source": [
    "#### Task 2: 手动检查训练集的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c62bee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 60000\n",
      "验证集大小: 10000\n",
      "图像形状: torch.Size([1, 28, 28])\n",
      "type of the lablel: <class 'int'>\n",
      "torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 手动查看数据集里的内容\n",
    "print(f\"训练集大小: {len(train_ds)}\")\n",
    "print(f\"验证集大小: {len(val_ds)}\")\n",
    "print(f\"图像形状: {train_ds[0][0].shape}\")\n",
    "print(f\"type of the lablel: {type(train_ds[0][1])}\")\n",
    "print(train_ds[0][0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c3c70",
   "metadata": {},
   "source": [
    "#### Question 1: train_ds是一个什么样的结构？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
